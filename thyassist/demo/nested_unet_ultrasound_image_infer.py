"""åŸºäºUNet++å’Œæ”¯æŒå‘é‡æœºçš„ç”²çŠ¶è…ºè¶…å£°å½±åƒåˆ†æ"""
import os
import subprocess
import signal
import sys
import cv2
import numpy as np
import onnxruntime as ort
import gradio as gr
from thyassist.machine_learning.dataloader import (download_svm_model,
                                                   load_svm_model,
                                                   extract_features_from_image)
from thyassist.machine_learning.utils import is_ascend_available, is_gpu_available
from launcher import get_project_root


download_dir = get_project_root()
my_theme = gr.themes.Soft(
    primary_hue="blue",
    secondary_hue="cyan",
    neutral_hue="gray",
    text_size="md",
    spacing_size="md",
    radius_size="md"
)


if not os.path.exists(os.path.join(download_dir, "svm_models")):
    download_svm_model()
else:
    pass

judge_echo_intensity_model , judge_echo_intensity_scaler = load_svm_model(os.path.join(download_dir, "svm_models",
                                                                                       "judge_echo_intensity_model.pkl"),
                                                                          os.path.join(download_dir, "svm_models",
                                                                                       "judge_echo_intensity_scaler.pkl"))
judge_microcalcification_model, judge_microcalcification_scaler = load_svm_model(os.path.join(download_dir, "svm_models",
                                                                                              "judge_microcalcification_model.pkl"),
                                                                          os.path.join(download_dir, "svm_models",
                                                                                       "judge_microcalcification_scaler.pkl"))
judge_solidity_model, judge_solidity_scaler = load_svm_model(os.path.join(download_dir, "svm_models",
                                                                          "judge_solidity_model.pkl"),
                                                                          os.path.join(download_dir,
                                                                                       "svm_models", "judge_solidity_scaler.pkl"))

USE_ORANGE_PI = False
USE_ACL = False
selected_provider = 'CPUExecutionProvider'

if is_ascend_available():
    # ä½¿ç”¨æ˜‡è…¾ç¡¬ä»¶è¿›è¡Œæ¨¡å‹æ¨ç†
    current_user = subprocess.run(['whoami'], capture_output=True, text=True, check=True).stdout.strip()
    if current_user == 'HwHiAiUser':  # å¦‚æœå½“å‰ç”¨æˆ·æ˜¯HwHiAiUser
        USE_ORANGE_PI = True
    try:
        import acl
        import acllite_utils as utils
        from acllite_model import AclLiteModel
        from acllite_resource import resource_list
        from thyassist.machine_learning.dataloader import download_nested_unet_om
        print("âœ… ä½¿ç”¨ Ascend ç¡¬ä»¶è¿›è¡Œæ¨¡å‹æ¨ç†")
        USE_ACL = True
    except FileNotFoundError:
        # pylint: disable=unused-import
        from thyassist.machine_learning.dataloader import download_resnet_onnx
        USE_ACL = False
        print("âš ï¸ NPUç¯å¢ƒä¾èµ–åŠ è½½å¼‚å¸¸ï¼Œå›é€€åˆ°CPUç¯å¢ƒè¿›è¡Œæ¨ç†")

elif is_gpu_available():
    # ä½¿ç”¨ NVIDIA GPUè¿›è¡Œæ¨¡å‹æ¨ç†
    from thyassist.machine_learning.dataloader import download_nested_unet_onnx
    selected_provider = 'TensorrtExecutionProvider'
    print("âœ… ä½¿ç”¨ NVIDIA GPU æ¨ç†")

else:
    # æ— ç¡¬ä»¶åŠ é€Ÿï¼Œä½¿ç”¨CPU
    from thyassist.machine_learning.dataloader import download_nested_unet_onnx
    print("âš ï¸ æ— å¯ç”¨ GPU/NPUï¼Œå›é€€åˆ° CPU è¿›è¡Œæ¨ç†")


# è‹¥è¿›ç¨‹ç»ˆæ­¢ï¼Œå°†é£æ‰‡é€Ÿåº¦é™ä½
def on_terminate(signum, frame):
    if USE_ORANGE_PI:
        os.system('sudo npu-smi set -t pwm-duty-ratio -d 30')
    sys.exit(0)

signal.signal(signal.SIGINT, on_terminate)
signal.signal(signal.SIGTERM, on_terminate)

if USE_ACL:
    # ä½¿ç”¨é¦™æ©™æ´¾ï¼Œå®šä¹‰pyaclç›¸å…³ç»„ä»¶
    if USE_ORANGE_PI:
        os.system('sudo npu-smi set -t pwm-duty-ratio -d 100')

    class AclLiteResource:
        """ACL Lite Resource management class"""

        def __init__(self, device_id=0):
            self.device_id = device_id
            self.context = None
            self.stream = None
            self.run_mode = None

        def init(self):
            """Initialize resources"""
            print("Initializing resources...")
            ret = acl.init()
            utils.check_ret("acl.init", ret)

            ret = acl.rt.set_device(self.device_id)
            utils.check_ret("acl.rt.set_device", ret)

            self.context, ret = acl.rt.create_context(self.device_id)
            utils.check_ret("acl.rt.create_context", ret)

            self.stream, ret = acl.rt.create_stream()
            utils.check_ret("acl.rt.create_stream", ret)

            self.run_mode, ret = acl.rt.get_run_mode()
            utils.check_ret("acl.rt.get_run_mode", ret)
            print("Resources initialized successfully")

        def __del__(self):
            print("Releasing ACL resources...")
            resource_list.destroy()
            if self.stream:
                acl.rt.destroy_stream(self.stream)
            if self.context:
                acl.rt.destroy_context(self.context)
            acl.rt.reset_device(self.device_id)
            print("Resources released successfully")

    acl_resource = AclLiteResource()
    acl_resource.init()
    model_path = os.path.join(download_dir, "nested_unet.om")
    if not os.path.exists(model_path):
        download_nested_unet_om()
    model = AclLiteModel(model_path)
else:
    # éé¦™æ©™æ´¾ç¯å¢ƒä½¿ç”¨checkpointsè¿›è¡Œæ¨ç†
    model_path = os.path.join(download_dir, "nested_unet.onnx")
    if not os.path.exists(model_path):
        download_nested_unet_onnx()

    if is_gpu_available():
        cache_dir = os.path.join(download_dir, 'trt_cache', 'nested_unet')
        os.makedirs(cache_dir, exist_ok=True)

        os.environ['ORT_TENSORRT_ENGINE_CACHE_ENABLE'] = '1'
        os.environ['ORT_TENSORRT_CACHE_PATH'] = cache_dir

        has_cache = any(fname.endswith('.engine') for fname in os.listdir(cache_dir))

        if not has_cache:
            print(f"ğŸ› ï¸ æ£€æµ‹åˆ°é¦–æ¬¡ä½¿ç”¨æ¨¡å‹ nested_unet.onnxï¼Œæ­£åœ¨æ„å»º TensorRT å¼•æ“ç¼“å­˜...")
        else:
            print(f"âœ… å·²æ£€æµ‹åˆ°æ¨¡å‹ nested_unet.onnx çš„ TensorRT ç¼“å­˜ï¼Œå°†ç›´æ¥åŠ è½½ã€‚")

    session = ort.InferenceSession(model_path, providers=[selected_provider])

# å®šä¹‰gradioçš„Interfaceç±»
def infer_ultrasound_image(image):
    if image.shape == 2:
        image = cv2.cvtColor(image, cv2.COLOR_GRAY2RGB)
    copied_image = np.copy(cv2.resize(image, dsize=(572, 572)))
    image = cv2.resize(image, dsize=(256, 256))

    if USE_ACL:
        context, _ = acl.rt.get_context()
        if context != acl_resource.context:
            acl.rt.set_context(acl_resource.context)
        input_array = np.expand_dims(image.astype(np.float32).transpose((2, 0, 1)), axis=0) / 127.5 - 1
        result = model.execute([input_array])
        output_as_numpy = np.argmax(result[0], axis=1).astype(np.uint8) * 255
        output_as_numpy = output_as_numpy.reshape(256, 256)
    else:
        input_array = np.expand_dims(image.astype(np.float32).transpose((2, 0, 1)), axis=0) / 127.5 - 1
        input_name = session.get_inputs()[0].name
        output_name = session.get_outputs()[0].name
        result = session.run([output_name], {input_name: input_array})
        output_as_numpy = np.argmax(result[0], axis=1).astype(np.uint8) * 255
        output_as_numpy = output_as_numpy.reshape(256, 256)

    kernel = np.ones((5, 5), np.uint8)
    opened_output = cv2.morphologyEx(output_as_numpy, cv2.MORPH_OPEN, kernel)
    processed_output = cv2.morphologyEx(opened_output, cv2.MORPH_CLOSE, kernel)
    resized_output = cv2.resize(processed_output, dsize=(572, 572))
    contours, _ = cv2.findContours(resized_output, cv2.RETR_TREE, cv2.CHAIN_APPROX_NONE)
    result_image = cv2.drawContours(np.copy(copied_image), contours, -1, (100, 255, 0), 1)

    result = ""
    if len(contours[0]) == 0:
        result = "æœªå‘ç°ç»“èŠ‚"
        return result_image, result

    flag = 0
    # è®¡ç®—ç»“èŠ‚åŒºåŸŸæ°´å¹³å’Œå‚ç›´çš„å¤–ç•ŒçŸ©å½¢
    x, y, w, h = cv2.boundingRect(contours[0])  # è·å–æ°´å¹³å‚ç›´çš„å¤–ç•ŒçŸ©å½¢ï¼›x,yå¯¹åº”çš„ç‚¹æ˜¯image[y][x]
    roi = cv2.cvtColor(copied_image, cv2.COLOR_RGB2GRAY)[y:y + h, x:x + w]  # è¾¹ç•ŒçŸ©å½¢åŒºåŸŸ

    if h - w > 10:
        result += "çºµæ¨ªæ¯”å¤§äº1 "
        flag += 3
    else:
        result += "çºµæ¨ªæ¯”å°äºæˆ–è¿‘ä¼¼ç­‰äº1 "

    roi = cv2.resize(roi, dsize=(32, 32))
    roi_features = extract_features_from_image(roi)
    echo_intensity_features_scaled = judge_echo_intensity_scaler.transform([roi_features])
    microcalcification_features_scaled = judge_microcalcification_scaler.transform([roi_features])
    solidity_features_scaled = judge_solidity_scaler.transform([roi_features])

    echo_intensity_prediction = judge_echo_intensity_model.predict(echo_intensity_features_scaled)
    microcalcification_prediction = judge_microcalcification_model.predict(microcalcification_features_scaled)
    solidity_prediction = judge_solidity_model.predict(solidity_features_scaled)



    if solidity_prediction[0] == 0:
        result += "å®æ€§ç»“èŠ‚ "
        flag += 2
        if echo_intensity_prediction[0] == 0:
            flag += 2
            result += "ä½å›å£°"
        else:
            flag += 1
    else:
        result += "å›Šæ€§ç»“èŠ‚ "

    if microcalcification_prediction[0] == 0:
        result += "æœ‰å¾®é’™åŒ–ç°è±¡ "
        flag += 1
    else:
        result += "æ— å¾®é’™åŒ–ç°è±¡ "

    grade_list = ["TR1", "TR1", "TR2", "TR3", "TR4 A", "TR4 B", "TR4 C", "TR5"]
    advice_list = ["æ¶æ€§å¯èƒ½â‰¤2%ï¼Œå»ºè®®æ ¹æ®è‡ªèº«éœ€æ±‚å†³å®šæ˜¯å¦è¿›ä¸€æ­¥æ£€æŸ¥",
              "æ¶æ€§å¯èƒ½â‰¤2%ï¼Œå»ºè®®æ ¹æ®è‡ªèº«éœ€æ±‚å†³å®šæ˜¯å¦è¿›ä¸€æ­¥æ£€æŸ¥",
              "æ¶æ€§å¯èƒ½â‰¤2%ï¼Œå»ºè®®æ ¹æ®è‡ªèº«éœ€æ±‚å†³å®šæ˜¯å¦è¿›ä¸€æ­¥æ£€æŸ¥",
              "æ¶æ€§å¯èƒ½ï¼œ5%ï¼Œå»ºè®®æ ¹æ®ç»“èŠ‚å¤§å°è¿›è¡Œéšè®¿æˆ–ç»†é’ˆç©¿åˆºæ´»æ£€",
              "æ¶æ€§é£é™©2%-10%ï¼Œå»ºè®®æ ¹æ®ç»“èŠ‚å¤§å°è¿›è¡Œéšè®¿æˆ–ç»†é’ˆç©¿åˆºæ´»æ£€",
              "æ¶æ€§é£é™©10%-50%ï¼Œå»ºè®®è¿›è¡Œéšè®¿æˆ–ç»†é’ˆç©¿åˆºæ´»æ£€",
              "æ¶æ€§å¯èƒ½çº¦50%-90%ï¼Œå¼ºçƒˆå»ºè®®è¿›è¡Œéšè®¿æˆ–ç»†é’ˆç©¿åˆºæ´»æ£€",
              "æ¶æ€§å¯èƒ½ï¼90%ï¼Œè¯·ç«‹å³è¿›è¡Œç»†é’ˆç©¿åˆºæ´»æ£€"]

    grade1 = grade_list[min(flag, 7)]
    grade2 = grade_list[min(flag + 1, 7)]
    advice1 = advice_list[min(flag, 7)]
    advice2 = advice_list[min(flag + 1, 7)]


    if grade1 == grade2:
        result += f"åˆæ­¥å®šçº§ä¸º{grade1}, {advice1}"
    else:
        result += f"è¯·è§‚å¯Ÿç»“èŠ‚å¤–è§‚ï¼Œè‹¥è¾¹ç•Œæ¸…æ™°ä¸”è§„åˆ™ï¼Œåˆ™åˆæ­¥å®šçº§ä¸º{grade1}ï¼Œ{advice1},è‹¥è¾¹ç•Œæ¨¡ç³Šä¸”ä¸è§„åˆ™ï¼Œåˆ™åˆæ­¥å®šçº§ä¸º{grade2}ï¼Œ{advice2}"
    return result_image, result

with gr.Blocks(theme=my_theme) as demo:
    gr.Markdown("<h1 style='text-align: center;'>åŸºäºUNet++çš„ç”²çŠ¶è…ºè¶…å£°æ£€æµ‹å™¨</h1>")
    gr.Markdown("### ä¸Šä¼ è¶…å£°å½±åƒï¼Œè·å–ç»“èŠ‚åŒºåŸŸä¿¡æ¯å’Œè¯Šæ–­å»ºè®®ã€‚")
    gr.Markdown("---")
    with gr.Row():
        # ç»™å›¾ç‰‡ç»„ä»¶è®¾ç½®è‡ªå®šä¹‰ CSS ID
        image_input = gr.Image(label="åŸå§‹è¶…å£°å›¾ç‰‡", elem_id="image_input_container")
        image_output = gr.Image(label="ç»“èŠ‚é¢„æµ‹ä½ç½®", elem_id="image_output_container")

    gr.Markdown("---")
    with gr.Row():
        text_output = gr.Textbox(label="svmé¢„æµ‹æŠ¥å‘Š", interactive=False, lines=2)

    gr.Markdown("---")

    with gr.Row():
        # æŒ‰é’®è§¦å‘å¤„ç†é€»è¾‘
        button = gr.Button("Execute")
        button.click(infer_ultrasound_image,
                     inputs=[image_input],
                     outputs=[image_output, text_output])  # è¾“å…¥åŸå§‹è¶…å£°å›¾åƒï¼Œè¾“å‡ºå¸¦è½®å»“è¶…å£°å›¾åƒåŠsvmé¢„æµ‹ç»“æœ

        # æ¸…é™¤æŒ‰é’®
        clear_button = gr.ClearButton(
            components=[image_input, image_output, text_output],  # æ¸…ç©ºé”™è¯¯ä¿¡æ¯
        )

demo.launch(inbrowser=True)
